{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONES DE ACTIVACIÓN Y COSTE PARA REDES NEURONALES MULTICAPA\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit,softmax\n",
    "\n",
    "class function(object):\n",
    "    def __init__(self,funcion,derivative=None,rand_init=(0,1)):\n",
    "        self.F=funcion\n",
    "        self.D=derivative\n",
    "        self.Rand_init=rand_init\n",
    "\n",
    "lineal=function(funcion=lambda x:x, derivative=lambda x:1, rand_init=(-1,1))\n",
    "sigm=function(funcion=lambda x: expit(x), derivative=lambda x: expit(x)*(1-expit(x)), rand_init=(0,1))\n",
    "tanh1=function(funcion=lambda x:np.tanh(x), derivative=lambda x:1-np.tanh(x)**2, rand_init=(-1,1))\n",
    "relu=function(funcion=lambda x: np.maximum(0, x), derivative=lambda x: np.where(x<=0,0,1), rand_init=(0,1))\n",
    "softmaxf=function(funcion=lambda x: softmax(x), derivative=lambda x:softmax(x)*(1-softmax(x)), rand_init=(0,1))\n",
    "tanh=function(funcion=lambda x:(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)),\n",
    "              derivative=lambda x:1-((np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))**2,\n",
    "              rand_init=(-1,1))\n",
    "Funciones={\"relu\":relu, \"sigm\":sigm, \"relu\":relu, \"tanh\":tanh, \"tanh1\":tanh1, \"lineal\":lineal, \"softmax\":softmaxf}\n",
    "\n",
    "mse=function(funcion=lambda Yp, Yr: np.mean((Yp - Yr) ** 2) , derivative=lambda Yp, Yr: (Yp - Yr))\n",
    "cross_entropy=function(funcion=lambda yscore,yreal:-np.sum(yreal*np.log(yscore))/yscore.shape[0],\n",
    "                       derivative=lambda yscore,yreal:yscore-yreal)\n",
    "Loss={\"mse\":mse, \"cross_entropy\":cross_entropy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958, 9) (689, 9) (173, 9) (96, 9)\n",
      "(958, 2) (689, 2) (173, 2) (96, 2)\n"
     ]
    }
   ],
   "source": [
    "# CARGA Y TRATAMIENTO DE DATOS\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1: TIC-TAC-TOE\n",
    "df = pd.read_csv(\"datasets/tic_tac_toe_dataset.csv\")\n",
    "df = df.replace(['x', 'b', 'o'], [0, 0.5, 1]) # Numeración de los estados de las carillas\n",
    "Y = pd.get_dummies(df['class']).to_numpy()\n",
    "X = df.drop('class', axis=1).to_numpy()\n",
    "\n",
    "\n",
    "# # 2: GENDER VOICE\n",
    "# df = pd.read_csv(\"datasets/gender_voice_dataset.csv\")\n",
    "# Y = pd.get_dummies(df.iloc[:, -1]).to_numpy()\n",
    "# df = df.iloc[:, :-1]\n",
    "# X = ((df-df.min())/(df.max()-df.min())).to_numpy()\n",
    "\n",
    "\n",
    "# # 3: \n",
    "# df = pd.read_csv(\"datasets/breast_cancer_dataset.csv\", header=None)\n",
    "# df = df[df.iloc[:,5] > -100000] # Filtro para los valores extraños\n",
    "# Y = pd.get_dummies(df.iloc[:, -1]).to_numpy()\n",
    "# df = df.iloc[:, :-1] / 10\n",
    "# X = df.to_numpy()\n",
    "\n",
    "\n",
    "# Dividimos los datos en 90% entrenamiento y 10% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "# Dividimos los datos de entrenamiento en 80% entrenamiento y 20% validación\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "\n",
    "# print(X, x_train, x_test, Y, y_train, y_test)\n",
    "print(np.shape(X), np.shape(x_train), np.shape(x_val), np.shape(x_test))\n",
    "print(np.shape(Y), np.shape(y_train), np.shape(y_val), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASE DE LA CAPA DE LA RED\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class neural_layer(object):\n",
    "    def __init__(self, n_conn, n_neur, activation=\"relu\"):\n",
    "        self.act = Funciones[activation]\n",
    "        self.activation=activation\n",
    "        self.random=self.act.Rand_init  \n",
    "        self.shape=(n_conn,n_neur)\n",
    "        self.Initialize()\n",
    "        \n",
    "    def show(self,Full=False):\n",
    "        print(f\"Pesos shape:{np.shape(self.W)} bias shape:{np.shape(self.b)} Activation:{self.activation}\")\n",
    "        print(f\"Activation:{self.activation}, Random:{self.random}\")\n",
    "        print(\"______________________\")\n",
    "        if Full:\n",
    "            print(f\"Pesos:\")\n",
    "            print(self.W)\n",
    "            print(\"#####\")\n",
    "            print(f\"Bias:\")\n",
    "            print(self.b)\n",
    "            \n",
    "    def Initialize(self):\n",
    "        self.b = np.random.uniform(*self.random,(1, self.shape[1]))      \n",
    "        self.W = np.random.uniform(*self.random,self.shape)\n",
    "        \n",
    "            \n",
    "#CLASE RED NEURONAL MULTICAPA        \n",
    "class Neural_Net(object):\n",
    "    def __init__(self,Input,loss):\n",
    "        self.loss = Loss[loss]\n",
    "        self.Funcion_Loss=loss\n",
    "        self.Input=Input\n",
    "        self.NN=None;\n",
    "              \n",
    "    def Add_Layer(self,Num_neurons, function):\n",
    "        if self.NN is None:\n",
    "            self.NN=[]\n",
    "            self.NN.append(neural_layer(self.Input,Num_neurons,function))\n",
    "        else:\n",
    "            _,L_input=np.shape(self.NN[-1].W)\n",
    "            self.NN.append(neural_layer(L_input,Num_neurons,function))\n",
    "            \n",
    "    def Show_Model(self, Full=False):\n",
    "        print(f\"Input shape:{self.Input}, Loss: {self.Funcion_Loss}\")\n",
    "        for i,L in enumerate(self.NN):\n",
    "            print(F\"Layer_{i}:\")\n",
    "            L.show(Full)\n",
    "            \n",
    "            \n",
    "    # fucnción de predicción (fordware pass)    \n",
    "    def Predict(self,X):  \n",
    "      #sólo podemos pasar Numpy  \n",
    "      sx=np.shape(X)\n",
    "      X=X.reshape(1,sx[0])\n",
    "      if self.NN is None:\n",
    "          print(\"error in Predict Method ( not NEURAL network available)\")\n",
    "          return 0\n",
    "        \n",
    "      out = [(None, X)] #primer data necesario\n",
    "      # Forward pass\n",
    "      for l, layer in enumerate(self.NN):\n",
    "          z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "          a = self.NN[l].act.F(z)\n",
    "          out.append((z, a))\n",
    "      return out[-1][1]\n",
    "    \n",
    "    \n",
    "    # función retropropagación del error\n",
    "    def _backward_pass(self, X, Y,lr=0.01, momentum=0):\n",
    "      sx=np.shape(X)\n",
    "      sy=np.shape(Y)   \n",
    "      X=X.reshape(1,sx[0])\n",
    "      Y=Y.reshape(1,sy[0])\n",
    "\n",
    "      # Forward pass\n",
    "      out = [(None, X)] #primer data necesario\n",
    "      for l, layer in enumerate(self.NN):\n",
    "            z = out[-1][1] @ self.NN[l].W + self.NN[l].b\n",
    "            a = self.NN[l].act.F(z)\n",
    "            out.append((z, a))\n",
    "\n",
    "      # Backward pass \n",
    "      deltas = []\n",
    "      for l in reversed(range(0, len(self.NN))):\n",
    "        z = out[l+1][0]\n",
    "        a = out[l+1][1]\n",
    "        if l == len(self.NN) - 1:\n",
    "            deltas.insert(0, self.loss.D(a, Y) * self.NN[l].act.D(a))\n",
    "        else:\n",
    "            deltas.insert(0, deltas[0] @ _W.T * self.NN[l-1].act.D(a))\n",
    "        _W = self.NN[l].W #los pesos en la capa superior\n",
    " \n",
    "        # Gradient descent\n",
    "        self.NN[l].b = self.NN[l].b - (deltas[0]* lr)\n",
    "        self.NN[l].W = self.NN[l].W - (lr * (out[l][1].T @ deltas[0])) # + momentum * la otra cosa\n",
    "      return out[-1][1]\n",
    "\n",
    "    # función de entrenamiento de la red\n",
    "    def Train(self,X,Y,valX=None,valY=None,lr=0.01,epoch=10,batch_size=1, momentum=0):\n",
    "        H_loss = {\"train\": [], \"val\": []}\n",
    "        H_acc = {\"train\": [], \"val\": []}\n",
    "        \n",
    "        # inicializamos las capas neuronales a valores ramdom del rango de la función\n",
    "        for Layer in self.NN:\n",
    "            Layer.Initialize()\n",
    "            \n",
    "        for i in range(epoch):\n",
    "            account=0\n",
    "            epoch_Loss=0\n",
    "            epoch_Acc=0\n",
    "            # Entrenemos a la red! con el dataset de validación\n",
    "            for j in range(len(X)):\n",
    "                pY = self._backward_pass(X[j,:], Y[j,:],lr,momentum)\n",
    "                epoch_Loss+=self.loss.F(pY[0],Y[j,:])\n",
    "                if (Y[j,:]==np.round(pY)).all():\n",
    "                    epoch_Acc+=1\n",
    "            H_acc[\"train\"].append(epoch_Acc/len(Y)*100)    \n",
    "            H_loss[\"train\"].append(epoch_Loss/len(Y))\n",
    "            \n",
    "            \n",
    "            #Validamos los datos\n",
    "            val_Loss=0\n",
    "            val_Acc=0\n",
    "            for k in range(len(valX)):\n",
    "                pY_val = self.Predict(valX[k])\n",
    "                val_Loss += self.loss.F(pY_val[0], valY[k,:])\n",
    "                if (valY[k,:]==np.round(pY_val)).all():\n",
    "                    val_Acc+=1\n",
    "            H_acc[\"val\"].append(val_Acc/len(valY)*100)    \n",
    "            H_loss[\"val\"].append(val_Loss/len(valY))\n",
    "            \n",
    "            #imprimimos por pantalla resultados\n",
    "            print(\"Epoch={}, Accuracy={} Loss={}, Val_Accuracy={} Val_Loss={}\"\n",
    "                  .format(i,round(H_acc[\"train\"][-1],3),round(H_loss[\"train\"][-1],7),\n",
    "                             round(H_acc[\"val\"][-1],3),round(H_loss[\"val\"][-1],7)))\n",
    "            clear_output(wait=True)\n",
    "        print(\"Epoch={}, Accuracy={} Loss={}, Val_Accuracy={} Val_Loss={}\"\n",
    "              .format(i,round(H_acc[\"train\"][-1],3),round(H_loss[\"train\"][-1],7),\n",
    "                         round(H_acc[\"val\"][-1],3),round(H_loss[\"val\"][-1],7)))\n",
    "        return H_loss,H_acc\n",
    "\n",
    "    \n",
    "# VISUALIZACIÓN Y TEST\n",
    "def Show_Loss_Acc(H_loss,H_acc):\n",
    "    plt.plot(range(len(H_loss[\"train\"])), H_loss[\"train\"],\"tab:blue\", \n",
    "             range(len(H_loss[\"val\"])), H_loss[\"val\"],\"tab:green\")\n",
    "    plt.ylabel(\"loss function \")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(H_acc[\"train\"])), H_acc[\"train\"], \"tab:red\",\n",
    "            range(len(H_acc[\"val\"])), H_acc[\"val\"], \"tab:orange\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"EPOCH NUMBER\")\n",
    "    plt.show()\n",
    "       \n",
    "def print_predict(neural_net,X,Y):\n",
    "    for i in range(len(X)):\n",
    "        sal_float=neural_net.Predict(X[i])\n",
    "        sal=np.round(sal_float)\n",
    "        \n",
    "        if (Y[i]==np.round(sal)).all():\n",
    "            print(\"Input:{}-- Real:{} predict: {} predict_float:{}\".format(X[i],Y[i],sal,np.round(sal_float,2)))\n",
    "        else:\n",
    "            print(\"\\x1b[31m Input:{}-- Real:{} predict: {} predict_float:{}\\x1b[0m\".format(X[i],Y[i],sal,np.round(sal_float,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIMOS LOS MODELOs\n",
    "_, x_input = x_train.shape\n",
    "_, y_output = y_train.shape\n",
    "# print(x_input, y_output)\n",
    "\n",
    "def Model_1_1():\n",
    "    red=Neural_Net(Input=x_input,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(10,\"relu\")\n",
    "    red.Add_Layer(y_output,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model_1_2():\n",
    "    red=Neural_Net(Input=x_input,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(18,\"sigm\")\n",
    "    red.Add_Layer(y_output,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model_2_1():\n",
    "    red=Neural_Net(Input=x_input,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(20,\"relu\")\n",
    "    red.Add_Layer(y_output,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model_2_2():\n",
    "    red=Neural_Net(Input=x_input,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(25,\"tanh\")\n",
    "    red.Add_Layer(y_output,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model_3_1():\n",
    "    red=Neural_Net(Input=x_input,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(20,\"relu\")\n",
    "    red.Add_Layer(6,\"sigm\")\n",
    "    red.Add_Layer(y_output,\"softmax\")\n",
    "    return red\n",
    "\n",
    "def Model_3_2():\n",
    "    red=Neural_Net(Input=x_input,loss=\"cross_entropy\")\n",
    "    red.Add_Layer(30,\"relu\")\n",
    "    red.Add_Layer(y_output,\"softmax\")\n",
    "    return red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:9, Loss: cross_entropy\n",
      "Layer_0:\n",
      "Pesos shape:(9, 10) bias shape:(1, 10) Activation:relu\n",
      "Activation:relu, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[2.35272924e-01 5.66569705e-02 6.79968500e-01 6.79943472e-01\n",
      "  2.16108325e-01 6.86401850e-01 1.89077523e-01 5.54300621e-01\n",
      "  3.71222040e-01 9.41172869e-01]\n",
      " [5.58658550e-01 7.74379742e-01 4.21968550e-01 6.34077728e-01\n",
      "  1.89388352e-01 9.31922586e-01 8.23196361e-01 6.92970446e-01\n",
      "  9.16512641e-01 3.84926323e-01]\n",
      " [8.19359902e-01 7.40989338e-01 9.83985180e-01 5.14367244e-01\n",
      "  3.11511184e-01 8.73490201e-02 3.59072868e-01 2.82773241e-02\n",
      "  6.32370557e-01 7.38282041e-02]\n",
      " [8.42289804e-01 3.17323967e-01 6.72397306e-01 5.05563727e-01\n",
      "  8.58925896e-01 9.20637324e-01 5.24588087e-01 2.18267117e-01\n",
      "  1.98001905e-01 2.69110896e-04]\n",
      " [4.63559047e-01 8.51009071e-01 8.78178799e-01 9.66053424e-01\n",
      "  2.88485163e-01 9.54645166e-01 5.29762414e-01 9.74686811e-01\n",
      "  9.45793649e-01 3.73149348e-02]\n",
      " [7.76258529e-01 1.86042732e-01 9.27050955e-01 2.78455569e-01\n",
      "  4.66797154e-01 5.29454065e-01 7.36724286e-01 2.87288547e-01\n",
      "  6.31548027e-01 4.34215243e-01]\n",
      " [9.25707702e-01 7.00821951e-01 9.83729267e-01 5.13472540e-01\n",
      "  9.45975576e-01 9.89796871e-01 7.76131307e-01 2.38046281e-01\n",
      "  6.14563722e-01 4.70209931e-01]\n",
      " [2.29145865e-01 3.93203984e-01 2.80347997e-01 7.13837459e-02\n",
      "  7.02191238e-01 1.99061830e-01 1.86725534e-01 5.76603713e-01\n",
      "  9.86496070e-01 2.65029811e-01]\n",
      " [7.87481557e-01 4.27081185e-01 3.69537780e-01 5.97674046e-01\n",
      "  6.81301887e-01 2.42901990e-01 7.48988093e-01 3.23869468e-01\n",
      "  2.51250944e-01 3.79323775e-01]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.27050557 0.02024806 0.60553315 0.53246287 0.08949853 0.81825509\n",
      "  0.74932342 0.88677302 0.01722278 0.93660443]]\n",
      "Layer_1:\n",
      "Pesos shape:(10, 2) bias shape:(1, 2) Activation:softmax\n",
      "Activation:softmax, Random:(0, 1)\n",
      "______________________\n",
      "Pesos:\n",
      "[[0.45754146 0.70854391]\n",
      " [0.00235822 0.9622931 ]\n",
      " [0.33256291 0.89871698]\n",
      " [0.18494685 0.1864086 ]\n",
      " [0.73006827 0.68667756]\n",
      " [0.57560729 0.10161094]\n",
      " [0.93003631 0.65576257]\n",
      " [0.9613435  0.01970177]\n",
      " [0.58846907 0.87770491]\n",
      " [0.11156724 0.40093253]]\n",
      "#####\n",
      "Bias:\n",
      "[[0.88761507 0.27807635]]\n"
     ]
    }
   ],
   "source": [
    "cnn=Model_1_1()\n",
    "# cnn.Show_Model()\n",
    "cnn.Show_Model(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-619848aa6109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mShow_Loss_Acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-181d7644177b>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, X, Y, valX, valY, lr, epoch, batch_size, momentum)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# Entrenemos a la red! con el dataset de validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mpY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mepoch_Loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-181d7644177b>\u001b[0m in \u001b[0;36m_backward_pass\u001b[0;34m(self, X, Y, lr, momentum)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mdeltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0m_W\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;31m# Pesos de la capa inferior * momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0m_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;31m#los pesos en la capa superior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 0 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "loss,accuracy=cnn.Train(x_train, y_train, x_val, y_val, 0.2, 30)\n",
    "Show_Loss_Acc(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:[0.5 1.  0.  0.  1.  0.  1.  0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.  0.  0.5 1.  0.  0.5 1.  0.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[1.  0.  0.  1.  1.  1.  0.  0.5 0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.98 0.02]]\n",
      "Input:[0.  0.  1.  0.  0.  0.5 1.  1.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  1.  0.  0.  1.  0.  0.5 1.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.93 0.07]]\n",
      "Input:[0.  0.5 1.  0.5 1.  0.  1.  0.5 0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  1.  0.5 0.5 0.  0.  1.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  0.  1.  0.5 0.  1.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.03 0.97]]\n",
      "Input:[1.  0.5 1.  0.  0.  0.  0.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.2 0.8]]\n",
      "Input:[0.5 0.  1.  1.  0.  1.  0.5 0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.5 0.  0.5 0.  0.5 0.  1.  1.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1. 1. 0. 0. 0. 0. 1. 0. 1.]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0. 1. 0. 1. 0. 0. 0. 1. 1.]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.5 1.  1.  0.  0.5 0.5 0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.5 0.5 1.  0.  0.  0.  1.  0.5 0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.04 0.96]]\n",
      "Input:[0.5 1.  0.5 0.  1.  0.5 0.  1.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.95 0.05]]\n",
      "Input:[1.  0.5 0.  0.  1.  0.  0.5 0.5 1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.98 0.02]]\n",
      "Input:[0.  0.  0.  1.  0.5 1.  0.5 0.5 0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  1.  0.5 0.  0.  1.  0.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.1 0.9]]\n",
      "Input:[0.  0.5 0.  1.  0.5 0.  1.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  1.  0.  1.  1.  0.5 0.  1.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.94 0.06]]\n",
      "Input:[0.  1.  0.  1.  0.5 0.  0.5 1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  0.  1.  0.5 1.  0.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.  0.  0.  0.  0.5 1.  1.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.5 0.5 0.  1.  1.  0.  0.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.  0.5 1.  1.  0.  1.  0.5 0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  0.  1.  1.  0.5 1.  0.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.  1.  0.5 0.5 1.  1.  0.  0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[0.5 0.  0.  0.5 0.  1.  1.  0.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.  0.5 1.  0.  0.  0.5 1.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.04 0.96]]\n",
      "Input:[0.  0.  0.5 0.  1.  0.5 0.  1.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.04 0.96]]\n",
      "Input:[1.  0.  1.  0.  1.  0.  0.5 0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[1. 0.]]\n",
      "Input:[0.  0.  0.5 1.  1.  1.  0.  0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[1. 0.]]\n",
      "Input:[0.5 0.5 0.  0.5 0.  1.  0.  0.5 1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[0.  0.5 0.5 1.  0.  1.  0.5 0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.5 0.5 0.  0.5 0.  0.5 0.  1.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[1.  0.  1.  0.  0.  0.  0.5 1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.1 0.9]]\n",
      "Input:[0.5 0.5 0.  1.  0.  0.  1.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.5 0.  1.  0.  1.  0.  1.  0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[1. 0.]]\n",
      "Input:[0.5 0.5 0.  1.  0.  1.  0.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.5 0.5 1.  0.  0.5 1.  0.  0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  0.5 1.  0.  1.  0.  0.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.03 0.97]]\n",
      "Input:[0.  0.  0.5 0.5 0.5 0.  1.  1.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  0.5 1.  0.5 0.  1.  0.5 0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[1.  1.  0.  1.  0.  0.5 0.  0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[0. 1. 1. 0. 0. 0. 0. 1. 1.]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.32 0.68]]\n",
      "Input:[1.  1.  0.  1.  0.5 0.  0.  0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  1.  1.  0.5 1.  0.  0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  0.  1.  1.  1.  0.5 1.  0.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1. 1. 0. 0. 0. 1. 0. 1. 0.]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.  0.5 0.  0.  1.  0.  1.  1.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.97 0.03]]\n",
      "Input:[0.  0.5 0.  0.  1.  0.5 0.  1.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[1.  0.  0.5 1.  0.5 0.  1.  0.5 0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1.  0.5 0.  0.5 0.  1.  0.  0.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[0.  1.  1.  0.  0.  0.  0.5 1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.13 0.87]]\n",
      "Input:[0.5 1.  0.  0.5 0.  0.5 0.  0.5 1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[1.  1.  1.  0.  0.5 0.  0.  1.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.98 0.02]]\n",
      "Input:[1.  0.  1.  0.  1.  0.  1.  0.  0.5]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[1. 0.]]\n",
      "Input:[1.  0.  1.  0.5 0.  1.  0.5 0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.09 0.91]]\n",
      "Input:[0.  0.  0.  1.  0.5 1.  0.5 0.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  1.  0.  0.5 0.5 0.  1.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[0.  0.  1.  0.5 1.  0.  1.  0.5 0.5]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  0.5 0.5 0.  0.5 1.  0.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.03 0.97]]\n",
      "Input:[0.  1.  0.5 0.  0.  0.  0.5 1.  1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.08 0.92]]\n",
      "Input:[0.  0.  1.  1.  1.  1.  0.5 0.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1.  1.  1.  0.5 0.5 0.  0.  0.5 0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.98 0.02]]\n",
      "Input:[0.  0.  1.  0.  1.  0.5 1.  1.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1.  1.  1.  0.  0.5 0.5 0.  0.5 0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.95 0.05]]\n",
      "Input:[0.5 0.5 1.  0.5 0.5 1.  0.  0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  0.  1.  0.  1.  0.5 1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  1.  0.  1.  0.5 1.  0.5 0.5]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.  1.  1.  0.  0.  1.  0.5 0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.5 1.  1.  0.  1.  0.  1.  0.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "\u001b[31m Input:[1. 1. 0. 0. 0. 1. 1. 0. 0.]-- Real:[1 0] predict: [[0. 1.]] predict_float:[[0.03 0.97]]\u001b[0m\n",
      "Input:[0.5 0.  1.  1.  0.  1.  0.  0.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.03 0.97]]\n",
      "Input:[0.  0.5 1.  0.5 0.5 1.  0.  0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[0.5 1.  0.  0.5 1.  0.  1.  0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\n",
      "Input:[0.5 1.  0.  0.  0.  0.  1.  0.5 1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.5 0.5 0.  1.  1.  0.  0.5 0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.  1.  0.  0.5 1.  1.  0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.98 0.02]]\n",
      "Input:[0.  0.5 0.5 0.  1.  0.5 0.  0.5 1. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[1.  0.5 0.5 1.  0.  0.  1.  0.5 0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.98 0.02]]\n",
      "Input:[0.  1.  0.5 1.  1.  0.5 0.  0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[0.  0.5 1.  0.  0.5 1.  0.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.04 0.96]]\n",
      "Input:[0.  1.  1.  0.  0.5 0.5 0.  1.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.05 0.95]]\n",
      "Input:[1.  0.  0.  1.  1.  0.  0.  0.5 1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[1. 0.]]\n",
      "Input:[1.  0.  0.  0.  1.  0.  0.5 1.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1.  0.  0.  0.  1.  0.  1.  0.5 1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1.  0.  0.  0.5 1.  0.5 0.  0.5 1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[1. 0.]]\n",
      "Input:[0.  1.  1.  0.  1.  0.5 1.  0.  0. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.97 0.03]]\n",
      "\u001b[31m Input:[1. 0. 0. 0. 1. 1. 0. 1. 0.]-- Real:[1 0] predict: [[0. 1.]] predict_float:[[0.02 0.98]]\u001b[0m\n",
      "Input:[1.  0.  0.  0.5 1.  0.5 0.5 0.  1. ]-- Real:[1 0] predict: [[1. 0.]] predict_float:[[0.99 0.01]]\n",
      "Input:[1.  0.5 0.  0.5 0.  0.5 0.  1.  0.5]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n",
      "Input:[1.  1.  0.5 0.5 0.  1.  0.  0.  0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0. 1.]]\n",
      "Input:[1.  1.  0.  0.  0.5 0.  1.  0.5 0. ]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.04 0.96]]\n",
      "Input:[0. 1. 1. 1. 1. 0. 0. 0. 0.]-- Real:[0 1] predict: [[0. 1.]] predict_float:[[0.01 0.99]]\n"
     ]
    }
   ],
   "source": [
    "print_predict(cnn, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
