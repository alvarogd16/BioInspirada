{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red convolucional con mecanismos atencionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-3b3dc022634f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-3b3dc022634f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    super(CBAM, self).__init__()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class ChannelModule(nn.Module):\n",
    "    def __init__(self, in_planes, reduction_ratio=16):\n",
    "        m_channelModule = models.Sequential()\n",
    "        m_channelModule.add()\n",
    "        \n",
    "    #def __init__(self, in_planes, reduction_ratio=16):\n",
    "        #super(ChannelGate, self).__init__()\n",
    "        #self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        #self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        #self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // reduction_ratio, 1, bias=False),\n",
    "        #                       nn.ReLU(),\n",
    "        #                       nn.Conv2d(in_planes // reduction_ratio, in_planes, 1, bias=False))\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    #def forward(self, x):\n",
    "        #avg_out = self.fc(self.avg_pool(x))\n",
    "        #max_out = self.fc(self.max_pool(x))\n",
    "        #out = avg_out + max_out\n",
    "        #return self.sigmoid(out) * x\n",
    "    \n",
    "class ChannelPool(nn.Module):\n",
    "    pass\n",
    "    \n",
    "    #def forward(self, x):\n",
    "        #return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_p, out_p, kernel, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False)\n",
    "        m_basicConv = models.Sequential()\n",
    "        m_basincConv.add(layers.Conv2D(CANTIDAD, (TAM,AÑO), activation='', input_shape=(CACA))) #PARAMETROS\n",
    "        if bn:\n",
    "            m_basicConv.add(BATCH_NORM_2D)\n",
    "        if relu:\n",
    "            # Añadir relu\n",
    "        return m_basicConv\n",
    "    \n",
    "    #def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        #super(BasicConv, self).__init__()\n",
    "        #self.out_channels = out_planes\n",
    "        #self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        #self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        #self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    #def forward(self, x):\n",
    "        #x = self.conv(x)\n",
    "        #if self.bn is not None:\n",
    "        #    x = self.bn(x)\n",
    "        #if self.relu is not None:\n",
    "        #    x = self.relu(x)\n",
    "        #return x\n",
    "    \n",
    "class SpatialModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        kernel_size = 7\n",
    "        m_spatialModule = models.Sequential()\n",
    "        m_spatialModule.add(CHANNEL_POOL)                                                       # +SIGMOIDE\n",
    "        m_spatialModule.add(BASIC_CONV(2, 1, kernel_size, stride=1, padding=(kernel-size-1)//2, relu=False))\n",
    "        ''' TODO\n",
    "        IN  imagen\n",
    "        DO  imagen --> channelPool --> basicConv --> sigmoide --> mapaCalor\n",
    "        OUT imagen * mapaCalor\n",
    "        '''\n",
    "    \n",
    "    #def __init__(self):\n",
    "        #super(SpatialGate, self).__init__()\n",
    "        #kernel_size = 7\n",
    "        #self.compress = ChannelPool()\n",
    "        #self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    #def forward(self, x):\n",
    "        #x_compress = self.compress(x)\n",
    "        #x_out = self.spatial(x_compress)\n",
    "        #scale = F.sigmoid(x_out) # broadcasting\n",
    "        #return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, channel, spatial):\n",
    "        m_cbam = models.Sequential()\n",
    "        if channel:\n",
    "            m_cbam.add(ChannelModule(gate_channels, reduction_ratio=reduction_ratio))\n",
    "        if spatial:\n",
    "            m_cbam.add(SpatialModule())\n",
    "        return m_cbam\n",
    "        \n",
    "    #def __init__(self, gate_channels, reduction_ratio=16, channel=True, spatial=True):\n",
    "        #super(CBAM, self).__init__()\n",
    "        #self.spatial=spatial\n",
    "        #self.channel=channel\n",
    "        #if channel:\n",
    "        #    self.ChannelGate = ChannelGate(gate_channels, reduction_ratio=reduction_ratio)\n",
    "        #if spatial:\n",
    "        #    self.SpatialGate = SpatialGate()\n",
    "    \n",
    "    #def forward(self, x):\n",
    "        #if self.channel:\n",
    "        #    x = self.ChannelGate(x)\n",
    "        #if self.spatial:\n",
    "        #    x = self.SpatialGate(x)\n",
    "        #return x\n",
    "\n",
    "\n",
    "class Convolutional(nn.Module):\n",
    "    def __init__(self, in_size):\n",
    "        m_convoluvional = models.Sequential()\n",
    "        m_convlucional.add(layers.Conv2D(CANTIDAD, (TAM,AÑO), activation='relu', input_shape=(CACA)))\n",
    "        m_convlucional.add(layers.MaxPooling2D((2, 2)))\n",
    "        m_convlucional.add(layers.Conv2D(CANTIDAD, (TAM,AÑO), activation='relu', input_shape=(CACA)))\n",
    "        m_convlucional.add(layers.MaxPooling2D((2, 2)))\n",
    "        return m_convolucional\n",
    "        \n",
    "    #def __init__(self, in_size):\n",
    "        #super(Convolutional, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(in_size, 6, 5)\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "    #def forward(self, x):\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        #return x\n",
    "\n",
    "\n",
    "# Clase constructora principal\n",
    "#   Encargada de utilizar el resto de clases para crear\n",
    "#   el modelo adecuado de red según los parámetros.\n",
    "class Model():\n",
    "    def __init__(self, channel, spatial):\n",
    "        m_model = models.Sequential()\n",
    "        m_model.add(layers.Conv2D(CANTIDAD, (TAM,AÑO), activation='', input_shape=(CACA)))\n",
    "        if channel or spatial:\n",
    "            m_model.add(CBAM(channel, spatial))\n",
    "        m_model.add(Convolutional(TAMAÑO_ENTRADA))\n",
    "        m_model.add(layers.Flatten())\n",
    "        m_model.add(layers.Dense(TAM_SALIDA, activation='linear'))\n",
    "        return m_model\n",
    "        \n",
    "    #def __init__(self, channel=True, spatial=True):\n",
    "        #super(model, self).__init__()\n",
    "        #self.att = channel_ or spatial_\n",
    "        #self.conv_ini = nn.Conv2d(3, 32, 1)\n",
    "        #if channel_ or spatial_:\n",
    "        #    self.layer1 = CBAM(32, spatial=spatial_, channel=channel_, reduction_ratio=16)\n",
    "        #self.layer2 = Convolutional(32)\n",
    "        #self.fc = nn.Linear(400, 10)\n",
    "    \n",
    "    #def forward(self, x):\n",
    "        #x = self.conv_ini(x)\n",
    "        #if self.att:\n",
    "        #    x = self.layer1(x)\n",
    "        #x = self.layer2(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        #x = self.fc(x)\n",
    "        #return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
